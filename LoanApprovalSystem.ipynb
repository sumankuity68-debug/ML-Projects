{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141e1781-cf38-41ed-a9c9-f77addb803bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9e9e3d-6f05-4478-b4c1-5444be77ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing Dtat\n",
    "data=pd.read_csv(\"C:\\\\Users\\\\suman\\\\Downloads\\\\loan_approval_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95063b8-d84f-4428-9861-8a6e9ee369a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Applicant_ID        950 non-null    float64\n",
      " 1   Applicant_Income    950 non-null    float64\n",
      " 2   Coapplicant_Income  950 non-null    float64\n",
      " 3   Employment_Status   950 non-null    object \n",
      " 4   Age                 950 non-null    float64\n",
      " 5   Marital_Status      950 non-null    object \n",
      " 6   Dependents          950 non-null    float64\n",
      " 7   Credit_Score        950 non-null    float64\n",
      " 8   Existing_Loans      950 non-null    float64\n",
      " 9   DTI_Ratio           950 non-null    float64\n",
      " 10  Savings             950 non-null    float64\n",
      " 11  Collateral_Value    950 non-null    float64\n",
      " 12  Loan_Amount         950 non-null    float64\n",
      " 13  Loan_Term           950 non-null    float64\n",
      " 14  Loan_Purpose        950 non-null    object \n",
      " 15  Property_Area       950 non-null    object \n",
      " 16  Education_Level     950 non-null    object \n",
      " 17  Gender              950 non-null    object \n",
      " 18  Employer_Category   950 non-null    object \n",
      " 19  Loan_Approved       950 non-null    object \n",
      "dtypes: float64(12), object(8)\n",
      "memory usage: 156.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Applicant_Income    950 non-null    float64\n",
      " 1   Coapplicant_Income  950 non-null    float64\n",
      " 2   Employment_Status   950 non-null    object \n",
      " 3   Age                 950 non-null    float64\n",
      " 4   Marital_Status      950 non-null    object \n",
      " 5   Dependents          950 non-null    float64\n",
      " 6   Credit_Score        950 non-null    float64\n",
      " 7   Existing_Loans      950 non-null    float64\n",
      " 8   DTI_Ratio           950 non-null    float64\n",
      " 9   Savings             950 non-null    float64\n",
      " 10  Collateral_Value    950 non-null    float64\n",
      " 11  Loan_Amount         950 non-null    float64\n",
      " 12  Loan_Term           950 non-null    float64\n",
      " 13  Loan_Purpose        950 non-null    object \n",
      " 14  Property_Area       950 non-null    object \n",
      " 15  Education_Level     950 non-null    object \n",
      " 16  Gender              950 non-null    object \n",
      " 17  Employer_Category   950 non-null    object \n",
      " 18  Loan_Approved       950 non-null    object \n",
      "dtypes: float64(11), object(8)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Getting Info about dataset\n",
    "data.info()\n",
    "data.isnull().sum()\n",
    "data=data.drop(columns=[\"Applicant_ID\"])\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a722b2-49f7-412d-853b-b5dc37f7ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing value \n",
    "#For numeric data missing value filled by mean of other data\n",
    "#For categorical data missing values filled by most frequent categories\n",
    "from sklearn.impute import SimpleImputer\n",
    "category_cols=data.select_dtypes(include=[\"object\"]).columns\n",
    "numeric_cols=data.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "num_imp=SimpleImputer(strategy=\"mean\")\n",
    "data[numeric_cols]=num_imp.fit_transform(data[numeric_cols])\n",
    "\n",
    "cat_imp=SimpleImputer(strategy=\"most_frequent\")\n",
    "data[category_cols]=cat_imp.fit_transform(data[category_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be6123-84cd-4c40-931b-156acb8705a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checing for outliers using box plots\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "sns.boxplot(ax=axes[0, 0], data=data, x=\"Loan_Approved\",y=\"Applicant_Income\")\n",
    "sns.boxplot(ax=axes[0, 1], data=data, x=\"Loan_Approved\",y=\"Credit_Score\")\n",
    "sns.boxplot(ax=axes[1, 0], data=data, x=\"Loan_Approved\",y=\"DTI_Ratio\")\n",
    "sns.boxplot(ax=axes[1, 1], data=data, x=\"Loan_Approved\",y=\"Savings\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43eedef-597c-46c5-bef6-e8958bebae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of reletion betwen Credit_Score and Loan_Approved ment status\n",
    "sns.histplot(\n",
    "    data=data,\n",
    "    x=\"Credit_Score\",\n",
    "    bins=20,\n",
    "    hue=\"Loan_Approved\",\n",
    "    multiple=\"dodge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296f109-2d3c-41df-b86e-adb3b1c89894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of reletion betwen DTI_Score and Loan_Approved ment status\n",
    "sns.histplot(\n",
    "    data=data,\n",
    "    x=\"DTI_Ratio\",\n",
    "    bins=20,\n",
    "    hue=\"Loan_Approved\",\n",
    "    multiple=\"dodge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83780cfd-1ee9-401b-b36a-d611cade9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of reletion betwen Applicant_Income and Loan_Approved ment status\n",
    "sns.histplot(\n",
    "    data=data,\n",
    "    x=\"Applicant_Income\",\n",
    "    hue=\"Loan_Approved\",\n",
    "    bins=20,\n",
    "    multiple=\"dodge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b20ef-9dcb-4887-8a9a-6d0f445d1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding done by lebel and onehot encoder\n",
    "#Education_level and result should give priority wise value \n",
    "#Other should have same contribution\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "lebelEncoder=LabelEncoder()\n",
    "data[\"Education_Level\"]=lebelEncoder.fit_transform(data[\"Education_Level\"])\n",
    "data[\"Loan_Approved\"]=lebelEncoder.fit_transform(data[\"Loan_Approved\"])\n",
    "\n",
    "oneHotEncoder=OneHotEncoder(drop=\"first\",sparse_output=False, handle_unknown=\"ignore\")\n",
    "column=[\"Employment_Status\", \"Marital_Status\", \"Loan_Purpose\", \"Property_Area\", \"Gender\", \"Employer_Category\"]\n",
    "encodedColums=oneHotEncoder.fit_transform(data[column])\n",
    "dataFrame=pd.DataFrame(encodedColums,columns=oneHotEncoder.get_feature_names_out(column),index=data.index)\n",
    "data=pd.concat([data.drop(columns=column),dataFrame],axis=1)\n",
    "\n",
    "\n",
    "# OneHotEncoding Using Pandas Library pd.get_dummies\n",
    "# column=[\"Employment_Status\", \"Marital_Status\", \"Loan_Purpose\", \"Property_Area\", \"Gender\", \"Employer_Category\"]\n",
    "# data=pd.get_dummies(data,columns=column,drop_first=True,dtype=float)\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad738d83-2f58-47d8-8556-bc7490287196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing the correlation between all features by Correlation heatmap\n",
    "number_columns=data.select_dtypes(include=\"number\")\n",
    "corr_matrix=number_columns.corr()\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\"\n",
    ")\n",
    "plt.title(\"Corelation Matrix\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc94e7-dad1-4089-8c4c-1dcadb9535d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_columns.corr()[\"Loan_Approved\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f091f7d-4edb-45e3-9010-5ad74836bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking input and output data\n",
    "X=data.drop(columns=[\"Loan_Approved\"])\n",
    "y=data[\"Loan_Approved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ec8c7-3597-4cbb-a403-f4e66cb91199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d58b1-1a51-4cb5-894d-ebae9ea3c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling data using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train_scale=scaler.fit_transform(X_train)\n",
    "X_test_scale=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211f072-e78e-47de-89ed-a028f75c604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train_scale, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test_scale)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression Model\")\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"CM: \", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bf80c-0c23-476b-8e93-521668cdbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Naive Byes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scale, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_scale)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Naive Bayes Model\")\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"CM: \", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42fb60-36d5-4c46-ac2b-b419203a4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying feature enginnering on this two columns because they have most impact in mode\n",
    "data[\"DTI_Ratio\"] = data[\"DTI_Ratio\"] ** 2\n",
    "data[\"Credit_Score\"] = data[\"Credit_Score\"] ** 2\n",
    "data[\"Applicant_Income_log\"] = np.log1p(data[\"Applicant_Income\"])\n",
    "\n",
    "X = data.drop(columns=[\"Loan_Approved\"])\n",
    "y = data[\"Loan_Approved\"]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d220c33-6cd4-4962-ae85-5fd7afdad662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed974d60-960b-4ea8-8b35-0e19fe088377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression Model\")\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"CM: \", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fad0d-c1b0-456b-a36e-d2783610163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Naive Bayes Model\")\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"CM: \", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0decf7a-3812-4569-aa6a-14c2ad314f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
